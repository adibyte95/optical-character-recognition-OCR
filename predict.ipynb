{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing dependencies\n",
    "import numpy as np\n",
    "import keras\n",
    "import os\n",
    "import cv2\n",
    "import imutils\n",
    "import os.path\n",
    "import importlib\n",
    "from os import listdir\n",
    "from keras import backend as k\n",
    "from keras.models import load_model\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = []\n",
    "# to get the name of the folder\n",
    "for name_folder in os.listdir(\"extracted_letter_images\") :\n",
    "    name = 'extracted_letter_images/' + name_folder\n",
    "    for f in listdir(name):\n",
    "        # name of the folder is the name of the output\n",
    "        y_train.append(np.asarray(name_folder))\n",
    "y_train = np.asarray(y_train)\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_segmentation(image_name):\n",
    "    # reading the image\n",
    "    image = cv2.imread(image_name)\n",
    "\n",
    "    # converting the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # threshold to convert the image to pure black and white\n",
    "    thresh = cv2.threshold(gray, 0,255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "\n",
    "\n",
    "    # find the contours (continous blob of pixels ) in the image \n",
    "    contours = cv2.findContours(thresh,cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Hack for compatibility with different OpenCV versions\n",
    "    contours = contours[0] if imutils.is_cv2() else contours[1]\n",
    "\n",
    "    letter_image_regions = []\n",
    "\n",
    "    # now loop through each of the letter in the image \n",
    "    for contour in contours:\n",
    "        # get the rectangle that contains the contour\n",
    "        x,y,w,h = cv2.boundingRect(contour)\n",
    "        # compare the width and height of the contour to detect if it\n",
    "        # has one letter or not\n",
    "        if w/h >1.25:\n",
    "            # this is too wide for a single letter\n",
    "            continue\n",
    "        elif w<3 or h<3:\n",
    "            # this is a very small image probably a noise\n",
    "            continue\n",
    "        else:\n",
    "        # this is a normal letter by itself\n",
    "            letter_image_regions.append((x,y,w,h))\n",
    "\n",
    "    return letter_image_regions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the trained model\n",
    "model = load_model('models/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 20, 20, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 10, 10, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 5, 5, 512)         590336    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               204900    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 32)                3232      \n",
      "=================================================================\n",
      "Total params: 872,964\n",
      "Trainable params: 872,964\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to resize the image into appropriate dimensions\n",
    "def resize(img):\n",
    "    img = cv2.resize(img,(20,20))\n",
    "    return img\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image no:  N73B8\n"
     ]
    }
   ],
   "source": [
    "# now we will read images from the folder segment the images and will produce the output\n",
    "for image_name in listdir('images'):\n",
    "    counter = 1\n",
    "    # constructing the name of the file \n",
    "    file_name = 'images/' + image_name\n",
    "\n",
    "    # getting segmented images \n",
    "    letters_in_image = image_segmentation(file_name)\n",
    "    \n",
    "    # sorting the letters so that letters that appear before is addressed first \n",
    "    letters_in_image = sorted(letters_in_image, key=lambda x: x[0])\n",
    "    \n",
    "    ans = \"\"\n",
    "    for (x,y,w,h) in letters_in_image:\n",
    "        image = cv2.imread(file_name,0)\n",
    "        letter = image[y - 2:y + h + 2, x - 2:x + w + 2]\n",
    "        \n",
    "        cv2.imwrite(str(counter)+'.jpg', letter)\n",
    "        counter = counter + 1\n",
    "        \n",
    "        letter  = resize(letter)/255\n",
    "        X_test = np.asarray(letter)\n",
    "        X_test = np.reshape(X_test, [-1,20,20,1])\n",
    "        output = np.argmax(model.predict(X_test, verbose = 0))\n",
    "        output = label_encoder.inverse_transform(output)\n",
    "        ans +=output\n",
    "    print(\"image no: \", ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
